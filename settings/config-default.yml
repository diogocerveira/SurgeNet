path_root: . #/batataclan
seed: 53  # 5 --> 3 or 3 --> 5  DO NOT CHANGE SEED (it messes up with fold training)
device:
id_classroom:  #LDSSi-2504-1 # if empty creates new learning environment, else loads it (dataset-YYMM-DDHH)
actions:
# - train        # train (spatial, temporal, full)
- process      # process (sample-n-label, mode-filter, extractFeatures)
# - eval         # eval (aprfc, phaseTiming, phaseChart)

# DATA and TRAIN properties define an unique classroom
DATA:
  id_dataset: LDSS-local  # (ldss-local, cifar10-ext)
  labelType: phase-class # time-to-next-phase, phase-label, time-to-video-end, time-since-video-start
  preprocessing: basic  # basic, augmentation
  recycle_itemIds: True  # for local dataset (__getitem__() returns the inputed frameIds to be used to fetch associated frame properties e.g. file path)
  datatype: png-image #, jpeg-image, feature-dict

TRAIN:
  train_point: start # (start, resume)
  path_resumeModel:  # to continue training from a checkpoint model if train-point == resume
  save_checkpoints: False
  checkpointRate: 6 # epoch frequency to save a checkpoint
  save_betterState: False
  save_lastState: True
  log_events: True
  criterionId: weighted-cross-entropy # weighted-cross-entropy
  train_metric: accuracy
  valid_metric: accuracy  # guiding and evaluating training
  k_folds: 7 # match with datasetName (7 for LDSS, 5 for CIFAR10, 1 for None?)
  skipFolds: []  # 0 for fold 1... after a break (e.g. crash) allows to skip folds and restart from a checkpoint
  HYPER:  # traditional hyperparameters
    n_epochs: 25
    batchSize: 16
    clipSize: 9  # amount of frames (sec) per clip when temporal training
    learningRate: 0.0005  # learning rate
    momentum: 0.9
    gamma: 0.1
    stepSize: 25  # optimizer scheduler (to change mid train)

PROCESS:  # Process
  sample: False

  samplerate: 1 # Hz
  sampleFormat: png
  filter_annotated: True
  resize: False
  path_rawVideos: /media/spaceship/ExternalDr/Data/Leuven_DS_Sacropexy
  path_sample: /media/spaceship/ExternalDr/Data/Leuven_DS_Sacropexy/samples/png-025

  label: False

  apply_modeFilter: False
  path_bundle: True
  export_modedPreds: True  # if apply-mode-filter == True
  
  fx_spatial: True
  fx_load_models: True
  featureLayer:
  - flatten

MODEL:  # for models created/trained in the run
  type: phase
  domain: spatial # spatial, temporal, full
# spatial
  spaceTransferLearning: fine-tune # fine-tune | fixed-fx
  spaceArch: resnet50
  spacePreweights: default # sfx = spatial feature extraction
  path_spaceModel: #C:/Users/DC/Documents/Programming/python/ucl/ML_SurgeNet/logs/LDSS/run_20241104-00/checkpoints/LDSS-20241104-00-fold6-0.837800.pth # if empty, uses new untrained one
# temporal
  timeArch: tcn # locked for now
  n_stages: 3
  n_kernels: 64  # number of convolution kernels per filter == number of channels
  tf_filter: 3  # size in time (timeframe, # of frames)
  n_blocks: 2  # inside the stage
# classification
  n_classes: 6  # normally gets from dataset itself 

EVAL:  # Eval
  eval_from: model  # model | predictions
  path_model:  # if eval-from == model and no training done
  path_preds:
  eval_tests:
    aprfc: True
    phaseTiming: True
    phaseChart: True
  export_testBundle: True
# metrics
  test_metrics:
    accuracy: True
    precision: True
    recall: True
    f1score: True
    confusionMatrix: True
  agg: macro  # overall, accuracy is locked to micro (see utils.py)
  updateRate: 1  # updates metrics with new data every batch
  computeRate: 100  # computes the metrics