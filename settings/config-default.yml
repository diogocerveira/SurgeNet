# General
seed: 53  # 5 --> 3 or 3 --> 5
device: None
path_root: .
run: #LDSS-24110400 # if not provided, creates new run
actions: 
- train        # train (spatial, temporal, full)
# - process      # process (sample, modeFitler, extractFeatures)
# - eval         # eval (aprfc, phaseTiming, phaseChart)

# Data
datakey: LDSS-local
preprocessing: basic  # basic, augmentation
extradata: # for local dataset (extends __getitem__() return beyond datapoint and label)
  sampleId: True
  videoId: False
  timestamp: False

# Model
modelkey: temporal # spatial, temporal, full
fx_weights: default
fx_model: logs/LDSS-24110400/train/checkpoints/LDSS-20241104-00-fold6-0.837800.pth
n_stages: 3
n_filters: 64  # number of convolution filters == number of channels inside a stage
filterTimeframe: 3  # size in time (# of frames)
n_resBlocks: 2  # inside the stage


# Train
train_point: start # (start, resume)
train_out:
  predictions: True
  checkpoints: True
  events: True
  bestModel: True
k_folds: 7 # match with datasetName (7 for LDSS, 5 for CIFAR10)
n_epochs: 50
batchSize: 128
criterion: crossEntropy
train_metric: accuracy
valid_metric: accuracy
hyperparameters:
  learningRate: 0.0005
  momentum: 0.9
  gamma: 0.1
  stepSize: 30  # optimizer scheduler (to change mid train)
path_resume: null  # to continue training from a checkpoint model
checkpointFrequency: 5 # epoch frequency to save a checkpoint
skipFolds: []  # 0 for fold 1...

# Process
process_in: 
processkeys:
  modeFilter: True
process_out:

# Eval
eval_in: pundle
path_model:
path_prediction:
evalkeys:
  aprfc: False
  phaseTiming: False
  phaseChart: False
eval_out:
  pundle: True
agg: macro  # accuracy is locked to micro (see utils.py)
updateFreq: 1  # updates metrics with new data every batch
computeFreq: 100  # computes the metrics
test_metrics:
  accuracy: True
  precision: True
  recall: True
  f1score: True
  confusionMatrix: True