path_root: . #/batataclan
path_data: #/workspace/raid-diogo/
seed: 53  # 5 --> 3 or 3 --> 5  DO NOT CHANGE SEED (it messes up with fold training)
device:
id_classroom: LDSS-2507-FX # if empty creates new learning environment, else loads it (dataset-YYMM-DDHH)
actions:
- train        # train (spatial, temporal, full)
# - process      # process (sample-n-label, mode-filter, extractFeatures)
- eval         # eval (aprfc, phaseTiming, phaseChart)

# DATA and TRAIN properties define an unique classroom
DATA:
  id_dataset: LDSS-local  # (LDSS-local, LDSSi-local, TEST-local, cifar10-ext)
  labelType: single-phase # time-to-next-phase, single-phase, time-to-video-end, time-since-video-start
  predicateLabels:
    - dissection
    - fixation
    - reperitonealisation
    # 0therPred
  objectLabels:
    - promontory
    - vault # same phase as right parasigmoidal gutter
    # 0therObj
# Full
     # - Dissection of the promontory
    # - Dissection of the right parasigmoidal gutter and the vault
    # - Fixation of the implant to the vault
    # - Fixation of the implant to the promontory
    # - Reperitonealisation
  preprocessing: basic  # basic, augmentation
  datatype: png-image #, jpeg-image, feature-dict

TRAIN: # to fix because the top ones should not define a classroom
  train_point: start # (start, resume)
  path_resumeModel:  # to continue training from a checkpoint model if train-point == resume
  save_checkpoints: False
  checkpointRate: 6 # epoch frequency to save a checkpoint
  save_betterState: True
  save_lastState: False
  log_events: True
  skipFolds: []  # 0 for fold 1... after a break (e.g. crash) allows to skip folds and restart from a checkpoint

  criterionId: weighted-cross-entropy # weighted-cross-entropy | binary-cross-entropy-logits
  criterionId: weighted-cross-entropy # weighted-cross-entropy | binary-cross-entropy-logits
  train_metric: accuracy
  valid_metric: accuracy  # guiding and evaluating training
  k_folds: 7 # number of folds for cross-validation
  minDelta: 0.001  # minimum delta to save a better state
  patience: 5  # number of epochs to wait for a better state before stopping training
  HYPER:  # traditional hyperparameters
    n_epochs: 100
    batchSize: 8
    clipSize: 500  # amount of frames (sec) per clip when temporal training
    learningRate: 0.0005  # learning rate
    momentum: 0.9
    gamma: 0.1
    stepSize: 25  # optimizer scheduler (to change mid train)

PROCESS:  # Process
  sample: False

  samplerate: 1 # Hz
  sampleFormat: png
  filter_annotated: True
  resize: False
  path_rawVideos: 
  path_sample:

  label: True

  apply_modeFilter: False
  path_bundle: True
  export_modedPreds: True  # if apply-mode-filter == True
  
  fx_spatial: True
  fx_load_models: True  #loads the spatial model to extract features if not training
  featureLayer:
  - flatten

MODEL:  # for models created/trained in the run
  type: phase
  domain: temporal # spatial, temporal, full
# spatial
  spaceTransferLearning: fixed-fx # fine-tune | fixed-fx
  spaceTransferLearning: fixed-fx # fine-tune | fixed-fx
  spaceArch: resnet50
  spacePreweights: default # sfx = spatial feature extraction
  path_spaceModel: #C:/Users/DC/Documents/Programming/python/ucl/ML_SurgeNet/logs/LDSS/run_20241104-00/checkpoints/LDSS-20241104-00-fold6-0.837800.pth # if empty, uses new untrained one
# temporal
  timeArch: tcn # locked for now
  n_stages: 3
  n_kernels: 64  # number of convolution kernels per filter == number of channels
  tf_filter: 3  # size in time (timeframe, # of frames)
  n_blocks: 2  # inside the stage
# classification
  n_classes:   # normally gets from dataset itself 

EVAL:  # Eval
  eval_from: model  # model | predictions
  path_model:  # if eval-from == model and no training done
  path_preds:
  eval_tests:
    aprfc: True
    phaseTiming: True
    phaseChart: True
  export_testBundle: True
# metrics
  test_metrics:
    accuracy: True
    precision: True
    recall: True
    f1score: True
    confusionMatrix: True
  agg: macro  # overall, accuracy is locked to micro (see utils.py)
  updateRate: 1  # updates metrics with new data every batch
  computeRate: 15  # computes the metrics