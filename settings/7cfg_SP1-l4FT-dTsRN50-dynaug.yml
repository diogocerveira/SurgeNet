path_root: . #/batataclan
path_data: #/workspace/raid-diogo/
seed: 53  # 5 --> 3 or 3 --> 5  DO NOT CHANGE SEED (it messes up with fold training)
device:
id_classroom:  # if empty creates new learning environment, else loads it (dataset-YYMM-DDHH)
actions:
- train        # train (spatial, temporal, full)
- process       # process (sample-n-label, mode-filter, extractFeatures)
- eval         # eval (aprfc, phaseTiming, phaseChart)

# DATA and TRAIN properties define an unique classroom
DATA:
  id_dataset: LDSS-local  # (LDSS-local, LDSSi-local, TEST-local, cifar10-ext)
  labelType: single-phase-top1 # time-to-next-phase, single-phase, time-to-video-end, time-since-video-start
  actionLabels:
    - dissection
    - fixation
    - reperitonealisation
    # 0Act  (Other Action)
  objectLabels:
    - promontory
    - vault
      # same phase as right parasigmoidal gutter
    # 0Obj  (Other Object)
# Full
    # - Dissection of the promontory
    # - Dissection of the right parasigmoidal gutter and the vault
    # - Fixation of the implant to the vault
    # - Fixation of the implant to the promontory
    # - Reperitonealisation
  preprocessing: imagenet-dynaug  # ldss, imagenet, augmentation
  multiClips: False
  multiClipStride: 3  # stride for multi-clip mode (e.g. 1, 2, 3)
  datatype: png-image #, jpeg-image, feature-dict

TRAIN: # to fix because the top ones should not define a classroom
  train_point: start # (start, resume)
  path_resumeModel:  # to continue training from a checkpoint model if train-point == resume
  save_checkpoints: False
  checkpointRate: 6 # epoch frequency to save a checkpoint
  save_betterState: True
  save_lastState: False
  log_events: True
  skipFolds: [] # 0 for fold 1... after a break (e.g. crash) allows to skip folds and restart from a checkpoint

  criterionId: weighted-cross-entropy # cross-entropy | weighted-cross-entropy | binary-cross-entropy-logits
  optimizerId: adam # adam | sgd
  schedulerId: step # step | cosine | plateau
  train_metric: accuracy
  valid_metric: accuracy  # guiding and evaluating training
  k_folds: 7 # number of folds for cross-validation
  HYPER:  # traditional hyperparameters
    n_epochs: 50
    spaceBatchSize: 32
    timeBatchSize: 1  # batch size for temporal training
    clipSize: 16  # amount of frames (sec) per clip when temporal training
    learningRate: 0.0001  # learning rate
    stepSize: 25  # optimizer scheduler (to change mid train)
    momentum: 0.9
    gamma: 0.1 # factor to scale learning rate by
    minDelta: 0.001  # minimum delta to save a better state
    patience: 5  # number of epochs to wait for a better state before stopping training

PROCESS:  # Process
  sample: False
  samplerate: 1 # Hz
  sampleFormat: png
  filter_annotated: True
  path_rawVideos: 
  path_sample:

  resize: False
  crop: False

  label: False

  apply_modeFilter: False
  path_bundle: True
  export_modedPreds: True  # if apply-mode-filter == True
  
  build_globalCM: True  # builds a global confusion matrix from all folds predictions

  fx_spatial: False
  featureLayer:
  - flatten
  # - layer4.2.relu_2
  fx_temporal: False
  fx_load_models: True  #loads models to extract features if not training
  
MODEL:  # for models created/trained in the run
  type: phase #Â images-frame # images-frame | imagesTs-frame | fmaps-clip
  domain: space-time # space, time, linear
# spatial
  spaceTransferMode: l4-fine-tune # fine-tune | feat-xtract | l4-fine-tune
  spaceArch: resnet50
  spacePreweights: image-net # image-net
  path_spaceModel: #C:/Users/DC/Documents/Programming/python/ucl/ML_SurgeNet/logs/LDSS/run_20241104-00/checkpoints/LDSS-20241104-00-fold6-0.837800.pth # if empty, uses new untrained one
  path_spaceFeats:
# temporal
  timeTransferMode: # fine-tune | feat-xtract
  timeArch: dTsNet # tecno | phatima | dTsNet | pTsNet
  n_stages: 3
  n_filters: 64  # number of convolution kernels per filter == number of channels
  tf_filter: 3  # size in time (timeframe, # of frames)
  n_blocks: 2 # inside the stage
  proj_channels: 5 # ts-net projection channels
# classification
  classifierArch: one-linear # one-liner | two-linear
  headType: 
  n_classes:   # normally gets from dataset itself 

EVAL:  # Eval
  eval_from: model  # model | predictions
  path_model:  # if eval-from == model and no training done
  path_preds:
  eval_tests:
    aprfc: True
    phaseTiming: True
    phaseChart: True
  export_testBundle: True
# metrics
  test_metrics:
    accuracy: True
    precision: True
    recall: True
    f1score: True
    confusionMatrix: True
  agg: macro  # overall, accuracy is locked to micro (see utils.py)
  updateRate: 1  # updates metrics with new data every batch
  computeRate: 3  # computes the metrics