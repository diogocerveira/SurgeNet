# General
seed: 53  # 5 --> 3 or 3 --> 5
device: None
path_root: "."
action: "train" # process (sample, fextract, modeFitler);
                # train (spatial, temporal);
                # eval (apref1coma, phaseTiming, phaseChart)

# Data
datakey: local # match with datasetName (local for LDSS, external for CIFAR10)
dataset: "LDSS_short" # LDSS, CIFAR10
prepkey: "basic"  # basic, augmentation
datapointExtra: # for local dataset (extend __getitem__() return beyond datapoint and label)
  datapointId: True

# Model
n_stages_G: 1  # G for Guesser
n_stages_R: 2  # R for Refiner
n_filters: 64  # number of convolution filters == number of channels inside a stage
filterTime: 3  # size in time
n_resBlocks_G: 2  # inside the stage
n_resBlocks_R: 2

# Process
processkey: fextract  # (sample, fextract, modeFilter)
fx_weights: "default"
fx_model: "LDSS-20241104-00--0.837800.pth"
fx_batchSize: 128  # training feature extractor

# Train
trainkey: "spatial" # spatial, temporal or modeFilter
k_folds: 7 # match with datasetName (7 for LDSS, 5 for CIFAR10)
n_epochs: 10
batchSize: 128
learningRate: 0.0005
momentum: 0.9
gamma: 0.1
stepSize: 30  # optimizer scheduler (to change mid train)
path_resume: null  # to continue training from a checkpoint model
checkpointFrequency: 5 # epoch frequency to save a checkpoint
skipFolds: []  # 0 for fold 1...

# Eval
evalkey:
  acpref1coma: False
  phaseTiming: False
  phaseChart: False
agg: "macro"  # accuracy is locked to micro (see utils.py)
updateFrequency: 1  # updates metrics with new data every batch
computeFrequency: 100  # computes the metrics

criterion: "crossEntropy"
metrics:
  train: "accuracy"
  valid: "accuracy"
  test: # metricSwitches
    accuracy: True
    precision: True
    recall: True
    f1score: True
    confusionMatrix: True


