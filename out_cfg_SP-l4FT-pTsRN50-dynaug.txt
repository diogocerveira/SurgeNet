nohup: ignoring input

A. [classroom] LDSS-2508-1 (Matched)
   [model] spatdurphase1 (Matched)
   For ('train', 'process', 'eval')

   Warning: Skipping annotation for 96c7 (./data/LDSS-local/annotations/96c7.json not found)
   Skipping hidden file _becb

   Skipping hidden file .DS_Store

   Skipping hidden file _2e98

   Skipping hidden file _d699

   Warning: Skipping annotation for b5bf (./data/LDSS-local/annotations/b5bf.json not found)
   A new labels.csv was created ./data/LDSS-local/labels/single-phase.csv
{0: '0Act-0Obj', 1: '0Obj-Rep', 2: 'Dis-Pro', 3: 'Dis-Vau', 4: 'Fix-Pro', 5: 'Fix-Vau'}
Phases (#6):  ['0Act-0Obj', '0Obj-Rep', 'Dis-Pro', 'Dis-Vau', 'Fix-Pro', 'Fix-Vau']
Class weights: tensor([0.3846, 0.6755, 1.0557, 0.2113, 3.4933, 0.1796])

B. [dataset] LDSS-local (#134498)
   [label] single-phase
   [preprocessing] imagenet-dynaug
   [classes] #6 (Unbalanced) ['0Act-0Obj', '0Obj-Rep', 'Dis-Pro', 'Dis-Vau', 'Fix-Pro', 'Fix-Vau']

   note: labels are formed automatically and sorted alphabetically,
      resulting in a different order from the annotations file. Fix-Vau comes before Fix-Pro!

C. [training] start on [device] cuda
   [folds] #7 [epochs] #25 [batch sizes] s32 / t1

  Fold 1 splits:
	train ['26d9', '315a', '436c', '5238', 'a909', 'b670', 'b71b', 'e6a9', 'e8d3', 'e8d7']
	valid ['a334', 'f63b']
	test ['cf7c']

    No 'path_spaceModel' found. Using pretrained resnet50 in l4-fine-tune mode.
    Feature size of 2048 at node 'flatten'

spacefmaps_f1
Feature path (spacefmaps_f1) not found in None

-------------- Epoch 1 --------------
	  T [E1 B1]   scr: 0.2812
	  T [E1 B1015]   scr: 0.7993
	  T [E1 B2029]   scr: 0.8444
	  T [E1 B3043]   scr: 0.8667
	  V [E1 B1]   scr: 0.6250
	  V [E1 B203]   scr: 0.6586
	  V [E1 B405]   scr: 0.6645
	  V [E1 B606]   scr: 0.6606
Train Loss: 0.361656	Valid Loss: 0.919054

* New best model (valid loss): inf --> 0.9191 *

-------------- Epoch 2 --------------
	  T [E2 B1]   scr: 0.9688
	  T [E2 B1015]   scr: 0.9298
	  T [E2 B2029]   scr: 0.9333
	  T [E2 B3043]   scr: 0.9357
	  V [E2 B1]   scr: 0.7812
	  V [E2 B203]   scr: 0.7286
	  V [E2 B405]   scr: 0.7209
	  V [E2 B606]   scr: 0.7220
Train Loss: 0.164616	Valid Loss: 0.991572
-------------- Epoch 3 --------------
	  T [E3 B1]   scr: 0.9688
	  T [E3 B1015]   scr: 0.9513
	  T [E3 B2029]   scr: 0.9510
	  T [E3 B3043]   scr: 0.9512
	  V [E3 B1]   scr: 0.6875
	  V [E3 B203]   scr: 0.6990
	  V [E3 B405]   scr: 0.7006
	  V [E3 B606]   scr: 0.7014
Train Loss: 0.121199	Valid Loss: 1.267229
-------------- Epoch 4 --------------
	  T [E4 B1]   scr: 0.9375
	  T [E4 B1015]   scr: 0.9612
	  T [E4 B2029]   scr: 0.9610
	  T [E4 B3043]   scr: 0.9620
	  V [E4 B1]   scr: 0.5000
	  V [E4 B203]   scr: 0.7084
	  V [E4 B405]   scr: 0.7137
	  V [E4 B606]   scr: 0.7155
Train Loss: 0.095186	Valid Loss: 1.118171

 Dataset augmentation strength increased to 0.2 

-------------- Epoch 5 --------------
	  T [E5 B1]   scr: 0.9688
	  T [E5 B1015]   scr: 0.9497
	  T [E5 B2029]   scr: 0.9517
	  T [E5 B3043]   scr: 0.9532
	  V [E5 B1]   scr: 0.6875
	  V [E5 B203]   scr: 0.6907
	  V [E5 B405]   scr: 0.6921
Traceback (most recent call last):
  File "learning.py", line 233, in <module>
    learning(**config)
  File "learning.py", line 86, in learning
    trainedModel, valid_maxScore, betterState = Tch.teach(model, trainloader, validloader, Csr.TRAIN["HYPER"]["n_epochs"], Csr.path_state, dset.labels, Csr.TRAIN["path_resumeModel"])
  File "/home/dcerveira/SurgeNet/src/teaching.py", line 75, in teach
    valid_loss, valid_score = self.validater.validate(model, validloader, self.labelType, labels, epoch)
  File "/home/dcerveira/SurgeNet/src/teaching.py", line 317, in validate
    runningLoss += loss.item() * targets.numel() # accumulate loss by batch size (safer, though most batches are same size)
RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

